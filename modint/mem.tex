\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper}
\usepackage{graphicx}
\usepackage{booktabs} 
\usepackage{array} 
\usepackage{paralist}
\usepackage{verbatim}

%\usepackage{subfig}
\usepackage{tikz}
\usepackage{amsmath,bm}
\usepackage{mathrsfs}
\usetikzlibrary{calc}
\usepackage{amssymb}
\usepackage{nccmath}
\usepackage{fancyhdr} 
\pagestyle{fancy} 
\renewcommand{\headrulewidth}{0pt}
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}
\usepackage{enumitem}   


\usepackage{titling}
\setlength{\droptitle}{-5em}   % This is your set screw

%\numberwithin{equation}{section}

\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\usepackage{etoolbox}
 \usepackage{relsize}

\usepackage{tikz,pgfplots}
\usepackage{tikz-3dplot}
\usetikzlibrary{shapes,calc,positioning}
\tdplotsetmaincoords{70}{120}
\usetikzlibrary{patterns}
\usepackage{parskip}

\usepackage{subcaption}

\usepackage{sectsty}
\sectionfont{\fontsize{12}{15}\selectfont}
%\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%\usepackage[compact]{titlesec}         % you need this package
%\titlespacing{\section}{2pt}{2pt}{2pt} % this reduces space between (sub)sections to 0pt, for example

\usepackage{pgfplots}
    % define a command which stores all commands that are needed for every
    % `raw gnuplot' call
    \newcommand*\GnuplotDefs{
        % set number of samples
        set samples 501;
        %
        % define beta distribution function
        % (copied from <http://gnuplot.sourceforge.net/demo/prob.5.gnu>)
        Binv(p,q)=exp(lgamma(p+q)-lgamma(p)-lgamma(q));
        beta(x,p,q)=p<=0||q<=0?1/0:x<0||x>1?0.0:Binv(p,q)*x**(p-1.0)*(1.0-x)**(q-1.0);
    }

\input{pre}

\makeatletter
\newcommand{\changeoperator}[1]{%
  \csletcs{#1@saved}{#1@}%
  \csdef{#1@}{\changed@operator{#1}}%
}
\newcommand{\changed@operator}[1]{%
  \mathop{%
    \mathchoice{\textstyle\csuse{#1@saved}}
               {\csuse{#1@saved}}
               {\csuse{#1@saved}}
               {\csuse{#1@saved}}%
  }%
}
\makeatother

\changeoperator{sum}
\changeoperator{prod}

\title{A modern interpretation of sequential approximate optimization}
\author{Dirk Munro (Hamburg, Germany)}
\date{\today } 
% Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\subsection{Introduction}

Assume we have an optimization problem $\mathcal{P}$ and an array of scalar decision variables $\bx$. The array of decision variables is assumed to be continuous and of length $n$, $\bx \in \mathbb{R}^n$. What is meant (herein\footnote{It is open to (largely academic) debate whether or not the definition implied here-in is traditionally correct. Traditionally, the `output' of the optimization problem $\mathcal{P}$ may be seen to be the decision variables at solution of the problem $\bx^\ast$. Herein we follow a more practical interpretation, insofar as we say that the problem $\mathcal{P}$ itself does not provide the solution $\bx^\ast$ as `output' (which is true).}) by `an optimization problem $\mathcal{P}$'? We will attempt a modern description, from a solution-method point-of-view. We assume that $\mathcal{P}$ is programmatic (numeric) entity, which may be evaluated with an array of particular decision (input) variable values $\bx$, $\mathcal{P}[\bx]$, and, in so doing, the problem returns the following information
\begin{align}
\label{d:eqn:p}
 ~\left\{ ~
\begin{aligned}
\bc &= (\c_0, \c_1, \ldots, \c_m ) \\
\dc & = (\dc_0 , \dc_1 , \ldots,\dc_m  ) \\ \underline{\overline{\bx}} & = ( \underline{\bx} , \: \overline{\bx} ) \:
\end{aligned}\right\} =
\mathcal{P} [\bx] \: .
\end{align}
That is 
\begin{enumerate}[label=(\roman*)]
  \item an array of scalar-valued cost-and-constraint functions $\bc$, of length $m$. We will adopt the convention that the first entry $\c_0$ is a scalar-valued objective (cost) to be minimised, and the following $m-1$ entries are scalar-valued constraint function values, with values of $\c_j \leq 0$ denoting feasibility; \emph{i.e.} adherence to constraint $j$, and violation otherwise;
  \item assuming each cost and constraint function is continuously differentiable, the first order derivatives of each, to each decision variable, $\dc$, with
\begin{equation}
\mathbf{\partial c }_j = \left( \frac{\partial \c_j}{\partial \x_1 } \:,  \frac{\partial \c_j}{\partial \x_2} \: , \ldots,  \frac{\partial \c_j}{\partial \x_n} \: \right) \quad \text{for} \quad j = 0,1, \ldots, m \:.
\end{equation}
  \item the  lower $\underline{\bx}$ and upper $\overline{\bx}$ bounds of the decision space, respectively, denoted by $\underline{\overline{\bx}}$.
  %upon evaluation with a particular $\bx$, that the problem $\mathcal{P}$ returns the remaining decision space (from the current evaluation point $\bx$) to the lower-bound of each variable $\Delta \underline{\bx}$, and likewise the remaining decision space to the upper-bound $\Delta \overline{\bx}$, collected in $\Delta \underline{\overline{\bx}}$.
\end{enumerate}

In other words, beyond the information we can collect from the quantities returned for particular evaluations $\left\{\bc, \partial \bc, \underline{\overline{\bx}}\right\}=\mathcal{P}[\bx]$ we have no further information of the problem $\mathcal{P}$, except for what can be deduced from the upstream assumptions (and knowledge of the nature of the problem). Moreover, in general, a single evaluation of problem $\mathcal{P}[\bx]$ is considered computationally expensive, insofar as it is non-trivially costly to evaluate in terms of computational resources---\emph{e.g.}, simulation-based, with multiple, potentially large-scale finite-element analyses.

How to find a candidate optimum solution $\bx^\ast$ of problem $\mathcal{P}$?  Well, we can start by sampling the decision space $\underline{\overline{\bx}}$, to find an $\bx$ with a reasonable cost $\c_0 [\bx]$, while all constraints are feasible $\c_j [\bx] \leq 0$, $\forall j > 0$. Then, we can ask the question: can this sample decision $\bx$ be improved if we adjust the evaluation in the decision space by a particular amount $\bx + \Delta \bx$? If there is a $\Delta \bx$ for which $\c_0 [\bx] > \c_0 [\bx + \Delta\bx]$, while all constraints remain feasible $\c_j [\bx + \Delta \bx] \leq 0$, $\forall j > 0$, then the sample $\bx$ we started with was indeed not optimal, and we should adjust the decision to $\bx + \Delta \bx$.

How to determine what $\Delta \bx$ should be? Keep in mind, we have assumed we are working with an expensive-to-evaluate problem $\mathcal{P}$, which only returns the information $\left\{\bc, \partial \bc, \underline{\overline{\bx}}\right\}=\mathcal{P}[\bx]$ upon evaluation at $\bx$. In practical terms, we will take this to mean that we want to compute a good change in the decision space $\Delta \bx$, without re-evaluating problem $\mathcal{P}$.

Let us, in hope\footnote{or desperation.}, assume that the actual cost-and-constraint functions $\bc$ are (near) linear over the entire decision space $\underline{\overline{\bx}}$. That is, an analytic linear approximation of the cost-and-constraint functions $\bc$, in terms of $\Delta \bx$, is constructed
\begin{equation}
\textbf{v}[\Delta \bx] = \bc + \partial \bc \cdot  \Delta \bx   \:,
\end{equation}
with first derivatives accordingly
\begin{equation}
\partial \textbf{v}[\Delta \bx] = \partial \bc \:.
\end{equation}
In general, the first-order approximation of the cost-and-constraint functions $\textbf{v}$ is only equal\footnote{Equal in zero-- and first-order information.} to the actual cost-and-constraint functions $\bc$ at $\bx$---i.e., with $\Delta \bx=\textbf{0}$---and representative in a infinitely small region around $\bx$. In the light of this, we introduce a lower $\Delta \underline{\bx}$ and upper $\Delta \overline{\bx}$ bound on the change $\Delta \bx$ we allow ourselves in the decision space $\underline{\overline{\bx}}$.
That is, we have arrived at a subproblem 
\begin{align}
\label{d:eqn:p}
 ~\left\{ ~
\begin{aligned}
\bv &= (\v_0, \v_1, \ldots, \v_m ) \\
\dv & = (\dv_0 , \dv_1 , \ldots,\dv_m  ) \\
%\partial^{2}\!\bv & = (\ddv_0 , \ddv_1 , \ldots,\ddv_m  ) \\
\Delta \underline{\overline{\bx}} & = ( \Delta \underline{\bx} , \: \Delta \overline{\bx} ) \:
\end{aligned}\right\} =
\mathcal{S} [\Delta \bx] \: ,
\end{align}
which is, importantly, unlike problem $\mathcal{P}$, very cheap to evaluate for different values of $\Delta \bx$. In general we say that a solution to problem $\mathcal{S}$---finding that $\Delta \bx$ in $\Delta \overline{\underline{\bx}}$ for which $\v_0$ is a minimum, while all $\v_j \leq 0$, $\forall j > 0$---is computable in polynomial time. Moreover, in practice, polynomial time solution methods are readily available.

We may thus, upon solving subproblem $\mathcal{S}$, update the decision to $\bx \gets \bx + \Delta \bx$; repeat the evaluation of problem $\mathcal{P}$ at the new values of the decision variables $\left\{\bc, \partial \bc, \underline{\overline{\bx}}\right\}=\mathcal{P}[\bx]$, and repeat the construction and solution of subproblem $\mathcal{S}$; until there is no change in the decision $\Delta \bx$ which improves the solution $\bx \to \bx^\ast$ of problem $\mathcal{P}$, further. 

In general, however, linear approximations $\bv$ of the cost-and-constraint functions $\bc$ may result in changes $\Delta \bx$ in the decision space which violates the constraints $\c_j[\bx + \Delta \bx] > 0 \: \forall j > 0$, increases in the cost function $\c_0[\bx + \Delta \bx]$, very restrictive allowable decision changes $\Delta \underline{\overline{\bx}}$ resulting in excessive, expensive evaluations of problem $\mathcal{P}$, and/or complete failure of the procedure to converge to a reasonable solution $\bx^\ast$ of problem $\mathcal{P}$.

What can we do...?

\subsection{Decision space transformations}

Let us assume that we notice, by observation, that the cost-and-constraint functions $\bc$ have a particular proportional relationship to decisions $\bx$ in the decision space $\underline{\overline{\bx}}$. For example, we might notice\footnote{and/or know, based on knowledge on the nature of the problem $\mathcal{P}$.} that the cost-and-constraint functions $\bc$ have a reciprocal-like relation to our decision variables, \emph{i.e.} $\bc \sim 1/\bx$. Can we exploit this to improve the change $\Delta \bx$ in the decision space we attempt to make? Yes, we can imagine applying an analytic transformation (mapping) to the decision space $\by = \by[\bx]$, and formulating the approximate cost-and-constraint functions $\textbf{v}$ in terms of it
\begin{equation}
\label{eq:intvar}
    \textbf{v} = \bc +   \partial_{\by} \bc \cdot \Delta \by \:.
\end{equation}
That is, we hope that the transformation of the decions space from $\bx \to \by$ has worked to `linearise' the cost-and-constraint functions $\bc$. Rewriting Eq. (\ref{eq:intvar}) in terms of the first-order information supplied by problem $\mathcal{P}$, we see that
\begin{equation}
    \textbf{v} = \bc + \partial \bc \cdot \partial_{\bx}^{-1} \by \cdot  \Delta \by    \:,
\end{equation}
with the derivative of the analytic mapping $\by = \by[\bx]$ easy to compute
\begin{equation}
    \partial_{\bx}^{-1} \by = \left. 1 \Big/ \frac{\partial \by}{\partial \bx}\right. \: .
\end{equation}
Note that  $\partial_{\bx}^{-1}\by$ is an $n \times n$ square matrix (although in practice, typically, only diagonal terms are utilised).

How does this help us? Consider again the example of the reciprocal transformation $\by = 1/ \bx$. In this case
\begin{equation}
\partial_{\bx}^{-1} \by = - \bx_{\bI}^2   \: ,
\end{equation}
with $_\bI$ indicating that the array is cast along the diagonal of the correspondingly sized square identity matrix. Hence
\begin{equation}
    \textbf{v} = \bc + \partial \bc  \cdot (-\bx_\bI^2) \cdot \Delta \by  \:.
\end{equation}
The approximate cost-and-constraint functions $\textbf{v}$ may be re-written in terms of the original decision space $\bx$ and the change $\Delta \bx$, which yields
\begin{equation}
    \textbf{v} = \bc + \partial \bc \cdot (-\bx_\bI^2)  \cdot \left( \frac{1}{ \bx + \Delta\bx} - \frac{1}{\bx} \right)   \:,
\end{equation}
and, is the same as
\begin{equation}
    \textbf{v} = \bc + \partial \bc  \cdot \left( \frac{\bx}{\bx + \Delta \bx} \right)_{\bI}\cdot \Delta \bx   \:.
\end{equation}
Notice how the term in brackets $(\cdots)$ has introduced a nonlinearity (or `curvature') in the approximate cost-and-constraint functions $\textbf{v}$, with respect to $\Delta \bx$. Keep in mind, the evaluation of problem $\mathcal{P} [\bx]$ is constant while we repeatedly evaluate (and solve) subproblem $\mathcal{S}[\Delta \bx]$, to compute the change in the decision space $\Delta \bx$. 

\subsection{Curvature information}

\bigskip

DRAFTING FOLLOWS...

\bigskip

Remains cheap to evaluate, and may be solved in polynomial time.

Now show curvature; introduce it in the subproblem output. And then show approx of approx, wherein curvature is constant wrt $\Delta \bx$

\newpage

In draft bits and pieces

Can we have an improved representation? Can we include information from upstream? We can introduce analytical nonlinearity (mainting cheapness) / nonlinear correction factor\footnote{Paragraph on intervening variables... Intervening variables are often used to introduce curvature known to be present due to physical reasons into an approximation, while retaining the simplicity of the first order Taylor series expansion. A nonlinear
approximation is normally obtained, even though only
first order sensitivity information is used in constructing the approximation. 

The real functions are replaced with explicit first order approximations...

Intermediate linearisation variables...

}
\begin{equation}
\textbf{v}[\Delta \bx] = \bc + \Delta \bx \cdot \partial \bc \cdot \bm{\varepsilon}[\Delta \bx]
\end{equation}
with first derivates then apadted to 
\begin{equation}
\partial \textbf{v}[\Delta \bx] = \partial \bc \cdot ( \Delta \bx \cdot \partial \bm{\varepsilon} + \bm{\varepsilon})
\end{equation}

Can be solved again. Note that we have introduced curvature into the subproblem; the second derivative is non-zero
\begin{equation}
\partial^2 \textbf{v}[\Delta \bx] = \partial \bc \cdot ( \Delta \bx \cdot \partial^2 \bm{\varepsilon} + 2 \partial \bm{\varepsilon})
\end{equation}

Another way to do this is to construct 


\newpage

IN DRAFT BITS AND PIECES

\begin{equation}
\textbf{v}[\Delta \bx] = \bc + \Delta \by[\Delta \bx] \cdot \partial_{\by}\bc
\end{equation}
rewritten in terms of the information we have
\begin{equation}
\textbf{v}[\Delta \bx] = \bc + \Delta \by[\Delta \bx] \cdot \partial \bc \cdot \partial_\by \bx
\end{equation}
and finally ... 



Now, because we know that $\textbf{v}$ is only a first-order approximation of the actual cost and constraint functions $\mathcal{c}$


\begin{equation}
\textbf{v}[\Delta \bx] = \bc + \partial \bc \cdot \Delta \bx + \frac{1}{2} \Delta \bx \cdot \partial^{2}\!\bv \cdot \Delta \bx
\end{equation}

\begin{equation}
\partial \textbf{v}[\Delta \bx] =  \partial \bc + \partial^{2}\!\bv \cdot  \Delta \bx
\end{equation}


\bigskip

in draft bits and pieces

\bigskip


To this end, we may define a sub-optimization problem $\mathcal{S}$
\begin{align}
\label{d:eqn:p}
 ~\left\{ ~
\begin{aligned}
\bv &= (\v_0, \v_1, \ldots, \v_m ) \\
\dv & = (\dv_0 , \dv_1 , \ldots,\dv_m  ) \\
\partial^{2}\!\bv & = (\ddv_0 , \ddv_1 , \ldots,\ddv_m  ) \\
\Delta \underline{\overline{\bx}} & = ( \Delta \underline{\bx} , \: \Delta \overline{\bx} ) \:
\end{aligned}\right\} =
\mathcal{S} [\Delta \bx] \: .
\end{align}
\bigskip

 $\left\{\bv, \partial \bv, \ddv,   \Delta \underline{\overline{\bx}}\right\}=\mathcal{S}[\bx]$ 



However, we have assumed that it is non-trivially costly to evaluate the problem $\mathcal{P}$, and hence we need to estimate what $\Delta\bx$ is required, without reevaluating $\left\{\bc, \partial \bc, \Delta \underline{\overline{\bx}}\right\}=\mathcal{P}[\bx]$. 


This information---whether or not it is possible to improve a candidate solution further---is of course contained in the values $\bc$ and the derivatives $\dc$ of the cost and constraint functions, and the remaining decision space to the bounds $\Delta \underline{\overline{\bx}}$.
%, returned by problem $\mathcal{P}$, at that particular evaluation $\bx$, $\mathcal{P}[\bx]$.

In other words, we have a sub-optimization-problem $\mathcal{S}$: in what direction and by how much should we change the decision variables $\Delta \bx$ to improve the cost function $\c_0[\bx + \Delta \bx]$, as much as possible, while maintaining feasibility $\c_j[\bx + \Delta \bx] \leq 0$, $\forall j > 0 $? Keep in mind, to remain consistent in the logical framework we have constructed, the subproblem $\mathcal{S}$ can not return a solution as output; it is evaluated at candidate (sub)solutions $\mathcal{S}[\Delta \bx]$, and particular quantities will be returned... [Notice how it is now logically clear that we need a cheap way to estimate what this delta should be (and a line-search by which we have to re-evaluate the problem P does not make sense); else, we have not done anything, we have just replaced an expensive problem without solution mapping with the same problem; the idea of cheap to evaluate surrogate functions now come into play, quite naturally I would say. At some point we have to go from problem to solution, and we have to do it in polynomial time.]

[Still busy; did not get further; but the logical tricks to get to cheap surrogate functions, which imply a simple mapping from problem to solution, is required here, now]

Eventually we arrive rather naturally at the necessary conditions: How far can we go, before we have to evaluate the problem again..? Keeping in mind, that we can not afford to evaluate the problem an excessive number of times... etc. etc. Move limits and estimates of nonlinear information (surrogate functions/problems, second order estimates).... upon convergence / when we can stop, we get something for free: the necessary conditions are satisfied / we have arrived at the necessary conditions in a rather practical way.

%Given the information from a particular evaluation(s) $\mathcal{P}[\bx]$, we can construct either a global or a local approximation of problem $\mathcal{P}$

% BIBLIOGRAPHY
\bibliographystyle{unsrt} 
\addcontentsline{toc}{chapter}{References} 
\bibliography{./bib.bib} 
\end{document}
