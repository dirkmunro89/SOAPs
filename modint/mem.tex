\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper}
\usepackage{graphicx}
\usepackage{booktabs} 
\usepackage{array} 
\usepackage{paralist}
\usepackage{verbatim}
\usepackage[implicit=false]{hyperref}

%\usepackage{subfig}
\usepackage{tikz}
\usepackage{amsmath,bm}
\usepackage{mathrsfs}
\usetikzlibrary{calc}
\usepackage{amssymb}
\usepackage{nccmath}
\usepackage{fancyhdr} 
\pagestyle{fancy} 
\renewcommand{\headrulewidth}{0pt}
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}
\usepackage{enumitem}   


\usepackage{titling}
\setlength{\droptitle}{-5em}   % This is your set screw

%\numberwithin{equation}{section}

\usepackage[symbol]{footmisc}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\usepackage{etoolbox}
 \usepackage{relsize}

\usepackage{tikz,pgfplots}
\usepackage{tikz-3dplot}
\usetikzlibrary{shapes,calc,positioning}
\tdplotsetmaincoords{70}{120}
\usetikzlibrary{patterns}
\usepackage{parskip}

\usepackage{subcaption}

\usepackage{sectsty}
\sectionfont{\fontsize{12}{15}\selectfont}
%\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%\usepackage[compact]{titlesec}         % you need this package
%\titlespacing{\section}{2pt}{2pt}{2pt} % this reduces space between (sub)sections to 0pt, for example

\usepackage{pgfplots}
    % define a command which stores all commands that are needed for every
    % `raw gnuplot' call
    \newcommand*\GnuplotDefs{
        % set number of samples
        set samples 501;
        %
        % define beta distribution function
        % (copied from <http://gnuplot.sourceforge.net/demo/prob.5.gnu>)
        Binv(p,q)=exp(lgamma(p+q)-lgamma(p)-lgamma(q));
        beta(x,p,q)=p<=0||q<=0?1/0:x<0||x>1?0.0:Binv(p,q)*x**(p-1.0)*(1.0-x)**(q-1.0);
    }

\input{pre}

\makeatletter
\newcommand{\changeoperator}[1]{%
  \csletcs{#1@saved}{#1@}%
  \csdef{#1@}{\changed@operator{#1}}%
}
\newcommand{\changed@operator}[1]{%
  \mathop{%
    \mathchoice{\textstyle\csuse{#1@saved}}
               {\csuse{#1@saved}}
               {\csuse{#1@saved}}
               {\csuse{#1@saved}}%
  }%
}
\makeatother

\changeoperator{sum}
\changeoperator{prod}

\title{On a modern interpretation of sequential approximate optimization}
\author{Dirk Munro (Hamburg, Germany)}
\date{\today } 
% Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle
\vspace{-8mm}
\small{\emph{This note is intended as a general yet simple introduction to the subject. No novelty beyond the interpretation, description (and notation) is introduced. The list of citations would not be reasonably complete without those referenced in the \textbf{Background}, in closure of the note.}}
\vspace{0mm}

\section{Introduction}
Assume we have an optimization problem $\mathcal{P}$ and an array of scalar decision variables $\bx$. Each decision variable is assumed to be continuous, and collected in an array of length $n$; \emph{i.e.} $\bx \in \mathbb{R}^n$. What is meant (herein\footnote{It is open to (largely academic) debate whether or not the definition implied here-in is traditionally correct. Traditionally, the `output' of the optimization problem $\mathcal{P}$ may be seen to be the decision variables at solution of the problem $\bx^\ast$. Herein we follow a more practical interpretation, insofar as we say that the problem $\mathcal{P}$ itself does not provide the solution $\bx^\ast$ as `output' (which is true).}) by `an optimization problem $\mathcal{P}$'? We will attempt a modern description, from a solution-method point-of-view. We assume that $\mathcal{P}$ is programmatic (numeric) entity, which may be evaluated with an array of particular decision (input) variable values $\bx$, $\mathcal{P}[\bx]$\footnote{Through-out square brackets $[\cdot]$ will denote an operation of `to evaluate at'; and it may be used and dropped freely as is relevant to the description of a particular entity, in a particular context.}, and, in so doing, the problem returns the following information
\begin{align}
\label{d:eqn:p}
 ~\left\{ ~
\begin{aligned}
\bc &= (\c_0, \c_1, \ldots, \c_m ) \\
\dc & = (\dc_0 , \dc_1 , \ldots,\dc_m  ) \\ \underline{\overline{\bx}} & = ( \underline{\bx} , \: \overline{\bx} ) \:
\end{aligned}\right\} =
\mathcal{P} [\bx] \: .
\end{align}
That is 
\begin{enumerate}[label=(\roman*)]
  \item an array of scalar-valued cost-and-constraint functions $\bc$, of length $m$. We will adopt the convention that the first entry $\c_0$ is a scalar-valued objective (cost) to be minimised, and the following $m-1$ entries are scalar-valued constraint function values, with values of $\c_j \leq 0$ denoting feasibility; \emph{i.e.} adherence to constraint $j$, and violation otherwise;
  \item assuming each cost and constraint function is (at least once) continuously differentiable, the first-order derivatives of each, to each decision variable, $\dc$, with
\begin{equation}
\mathbf{\partial c }_j = \left( \frac{\partial \c_j}{\partial \x_1 } \:,  \frac{\partial \c_j}{\partial \x_2} \: , \ldots,  \frac{\partial \c_j}{\partial \x_n} \: \right) \quad \text{for} \quad j = 0,1, \ldots, m \:;
\end{equation}
  \item the  lower $\underline{\bx}$ and upper $\overline{\bx}$ bounds\footnote{It is again interesting (but somewhat arbitrary) whether or not the (global) bounds on the decision space $\underline{\overline{\bx}}$ is taken to be defined in, and provided by, the problem $\mathcal{P}$. Practically, it is perhaps useful to interpret the bounds provided by problem $\mathcal{P}$ as restrictions on the extent of the decision space $\underline{\overline{\bx}}$ which follow naturally from the physics or character of the decision variables---\emph{e.g.} the range of thickness (greater than zero, but not infinite) permitted to a structural member. But of course, the decision / optimization algorithm, which operates on the information provided by problem $\mathcal{P}$, may (and typically will) operate iteratively in smaller decision spaces, overwriting the bounds provided by problem $\mathcal{P}$.} of the decision space, respectively, denoted by $\underline{\overline{\bx}}$.
  %upon evaluation with a particular $\bx$, that the problem $\mathcal{P}$ returns the remaining decision space (from the current evaluation point $\bx$) to the lower-bound of each variable $\Delta \underline{\bx}$, and likewise the remaining decision space to the upper-bound $\Delta \overline{\bx}$, collected in $\Delta \underline{\overline{\bx}}$.
\end{enumerate}

In other words, beyond the information we can collect from the quantities returned for particular evaluations $\left\{\bc, \partial \bc, \underline{\overline{\bx}}\right\}=\mathcal{P}[\bx]$ we have no further information of the problem $\mathcal{P}$, except for what can be deduced from the upstream assumptions (and knowledge of the nature of the problem). Moreover, in general, a single evaluation of problem $\mathcal{P}[\bx]$ is considered computationally expensive---or inconvenient, at least---insofar as it is non-trivially costly to evaluate in terms of computational resources and/or available channels of computational integration. That is simulation-based, with multiple, potentially large-scale finite-element analyses, but also computationally cheap (\emph{e.g.} reduced-order) analyses, which sit behind licensed applications and/or require significant network communications (\emph{e.g.} cloud-based microservices).

How to find a candidate\footnote{In general the optimization problem is assumed to be multi-modal. The topic is discussed, and a solution method is proposed, in \cite{munro2022}.} optimum solution $\bx^\ast$ of problem $\mathcal{P}$?  Well, we can start by sampling the decision space $\underline{\overline{\bx}}$, to find an $\bx$ with a reasonable cost $\c_0 [\bx]$, while all constraints are feasible $\c_j [\bx] \leq 0$, $\forall j > 0$. Then, we can ask the question: can this sample decision $\bx$ be improved if we adjust the evaluation in the decision space by a particular amount $\bx + \Delta \bx$? If there is a $\Delta \bx$ for which $\c_0 [\bx] > \c_0 [\bx + \Delta\bx]$, while all constraints remain feasible $\c_j [\bx + \Delta \bx] \leq 0$, $\forall j > 0$, then the sample $\bx$ we started with was indeed not optimal, and we should adjust the decision to $\bx + \Delta \bx$.

How to determine what $\Delta \bx$ should be? Keep in mind, we have assumed we are working with an expensive-to-evaluate problem $\mathcal{P}$, which only returns the information $\left\{\bc, \partial \bc, \underline{\overline{\bx}}\right\}=\mathcal{P}[\bx]$ upon evaluation at $\bx$. In practical terms, we will take this to mean that we want to compute a good change in the decision space $\Delta \bx$, without re-evaluating problem $\mathcal{P}$.

Let us, in hope\footnote{or desperation.}, assume that the actual cost-and-constraint functions $\bc$ are (near) linear over the entire decision space $\underline{\overline{\bx}}$. That is, an analytic linear approximation of the cost-and-constraint functions $\bc$, in terms of $\Delta \bx$, is constructed
\begin{equation}
\textbf{v}[\Delta \bx] = \bc + \partial \bc \cdot  \Delta \bx   \:,
\end{equation}
with first derivatives following accordingly
\begin{equation}
\partial \textbf{v}[\Delta \bx] = \partial \bc \:.
\end{equation}
In general, the first-order approximation of the cost-and-constraint functions $\textbf{v}$ is only equal\footnote{Equal in zero-- and first-order information.} to the actual cost-and-constraint functions $\bc$ at $\bx$---i.e., with $\Delta \bx=\textbf{0}$---and representative in a infinitely small region around $\bx$. In the light of this, we introduce a lower $\Delta \underline{\bx}$ and upper $\Delta \overline{\bx}$ bound on the change $\Delta \bx$ we allow ourselves in the decision space $\underline{\overline{\bx}}$.
That is, we have arrived at a subproblem 
\begin{align}
\label{d:eqn:p}
 ~\left\{ ~
\begin{aligned}
\bv &= (\v_0, \v_1, \ldots, \v_m ) \\
\dv & = (\dv_0 , \dv_1 , \ldots,\dv_m  ) \\
%\partial^{2}\!\bv & = (\ddv_0 , \ddv_1 , \ldots,\ddv_m  ) \\
\Delta \underline{\overline{\bx}} & = ( \Delta \underline{\bx} , \: \Delta \overline{\bx} ) \:
\end{aligned}\right\} =
\mathcal{S} [\Delta \bx] \: ,
\end{align}
which is, importantly, unlike problem $\mathcal{P}$, very cheap to evaluate for different values of $\Delta \bx$. In general we say that a solution to problem $\mathcal{S}$---finding that $\Delta \bx$ in $\Delta \overline{\underline{\bx}}$ for which $\v_0$ is a minimum, while all $\v_j \leq 0$, $\forall j > 0$---is computable in polynomial time. Moreover, in practice, polynomial time solution methods are readily available.

We may thus, upon solving subproblem $\mathcal{S}$, update the decision to $\bx \gets \bx + \Delta \bx$; repeat the evaluation of problem $\mathcal{P}$ at the new values of the decision variables $\left\{\bc, \partial \bc, \underline{\overline{\bx}}\right\}=\mathcal{P}[\bx]$, and repeat the construction and solution of subproblem $\mathcal{S}$ \emph{ad infinitum}, or, until there is no change in the decision $\Delta \bx$ which improves the solution $\bx \to \bx^\ast$ of problem $\mathcal{P}$, further. 

In general, however, linear approximations $\bv$ of the cost-and-constraint functions $\bc$ may result in changes $\Delta \bx$ in the decision space which violates the constraints $\c_j[\bx + \Delta \bx] > 0 \: \forall j > 0$, increases in the cost function $\c_0[\bx + \Delta \bx]$, very restrictive allowable decision changes $\Delta \underline{\overline{\bx}}$ resulting in excessive, expensive evaluations of problem $\mathcal{P}[\bx]$, and/or complete failure of the procedure to converge to a reasonable solution $\bx^\ast$ of problem $\mathcal{P}$.

What can we do?

\section{Decision space transformations}

Let us assume that we notice, by observation, that the cost-and-constraint functions $\bc$ have a particular proportional relationship to decisions $\bx$ in the decision space $\underline{\overline{\bx}}$. For example, we might notice\footnote{and/or know, based on knowledge on the nature of the problem $\mathcal{P}$.} that the cost-and-constraint functions $\bc$ have a reciprocal-like relation to our decision variables, \emph{i.e.} $\bc \sim 1/\bx$. Can we exploit this to improve the change $\Delta \bx$ in the decision space we attempt to make? Yes, we can imagine applying an analytic transformation (mapping) to the decision space $\by = \by[\bx]$, and formulating the approximate cost-and-constraint functions $\textbf{v}$ in terms of it
\begin{equation}
\label{eq:intvar}
    \textbf{v} = \bc +   \partial_{\by} \bc \cdot \Delta \by \:.
\end{equation}
That is, we hope that the transformation of the decions space from $\bx \to \by$ has worked to `linearise' the cost-and-constraint functions $\bc$. Rewriting Eq. (\ref{eq:intvar}) in terms of the first-order information supplied by problem $\mathcal{P}$, we retrieve
\begin{equation}
    \textbf{v} = \bc + \partial \bc \cdot \partial_{\bx}^{-1} \by \cdot  \Delta \by    \:,
\end{equation}
with the derivative of the analytic mapping $\by = \by[\bx]$ easy to compute
\begin{equation}
    \partial_{\bx}^{-1} \by = \left. 1 \Big/ \frac{\partial \by}{\partial \bx}\right. \: .
\end{equation}
Note that  $\partial_{\bx}^{-1}\by$ is an $n \times n$ square matrix (although in practice, typically, only diagonal terms are utilised).

How does this help us? Consider again the example of the reciprocal transformation $\by = 1/ \bx$. In this case
\begin{equation}
\partial_{\bx}^{-1} \by = - \bx_{\bI}^2   \: ,
\end{equation}
with $_\bI$ indicating that the array is cast along the diagonal of the correspondingly sized square identity matrix. Hence
\begin{equation}
    \textbf{v} = \bc + \partial \bc  \cdot (-\bx_\bI^2) \cdot \Delta \by  \:.
\end{equation}
The approximate cost-and-constraint functions $\textbf{v}$ may be re-written in terms of the original decision space $\bx$ and the change $\Delta \bx$, which yields
\begin{equation}
    \textbf{v} = \bc + \partial \bc \cdot (-\bx_\bI^2)  \cdot \left( \frac{1}{ \bx + \Delta\bx} - \frac{1}{\bx} \right)   \:,
\end{equation}
and, is the same as
\begin{equation}
    \textbf{v} = \bc + \partial \bc  \cdot \left( \frac{\bx}{\bx + \Delta \bx} \right)_{\bI}\cdot \Delta \bx   \:.
\end{equation}
Notice how the term in brackets $(\cdots)$ has introduced a analytically available nonlinearity (or `curvature') in the approximate cost-and-constraint functions $\textbf{v}$, with respect to $\Delta \bx$. Keep in mind, the evaluation of problem $\mathcal{P} [\bx]$ is constant while we repeatedly evaluate (and solve) subproblem $\mathcal{S}[\Delta \bx]$---which remains cheap to evaluate---to compute the change in the decision space $\Delta \bx$. 

Similarly, a decision space transformation may be generalised to the form $\by = \bx_\bI^a$, with $a$ any real number. In this case
\begin{equation}
\partial_{\bx}^{-1} \by = \frac {1}{a} \bx_{\bI}^{1-a}   \: ,
\end{equation}
and hence
\begin{equation}
    \bv = \bc + \partial \bc \cdot \frac {1}{a}  \bx_\bI^{1-a}  \cdot \left( (\bx + \Delta\bx)^a - \bx^a \right)   \:,
\end{equation}
which is easily evaluated for different values of $\Delta \bx$, with any manner of estimate for $a$. The first derivates of the approximate cost-and-constraint functions $\bv$ follow readily
\begin{equation}
\partial\bv[\Delta \bx] = \partial \bc \cdot (\bx^{1-a}) \cdot (\bx + \Delta \bx)^{a-1} \:,
\end{equation}
with the first-order information of problem $\mathcal{P}$ at the current evaluation point $\bx$, $\partial \bc$, retrieved for $\Delta \bx = \0$. 

\section{Taylor series expansions}
The analytic nonlinearity introduced by the decision space transformation is conveniently unpacked by Taylor series expansion $\bm{\nu}$, of the transformed cost-and-constraints $\bv$, in terms of $\Delta \bx$, away from the current decision point $\bx$:
\begin{equation}
\bm{\nu}[\Delta \bx] = \bv[\bx] + \frac{1}{1!}\partial \bv \cdot (\bx + \Delta \bx) + \frac{1}{2!}\partial^2 \bv \cdot (\bx + \Delta \bx)^2 + \frac{1}{3!}\partial^3 \bv \cdot (\bx + \Delta \bx)^3 + \ldots .
\end{equation}
For sake of simplicity, let us truncate after the first nonlinear (2nd) term
\begin{equation}
\bm{\nu}[\Delta \bx] = \bv[\bx] + \partial \bv \cdot (\bx + \Delta \bx) + \frac{1}{2}\partial^2 \bv \cdot (\bx + \Delta \bx)^2 \: , 
\end{equation}
noting that the second-derivative of the transformed cost-and-constraints $\bv$ is readily available
\begin{equation}
\partial^2 \bv[\Delta \bx] = \partial \bc \cdot (a-1)\bx^{1-a} \cdot (\bx+\Delta\bx)^{a-2} \: ,
\end{equation}
and, at the current decision point $\Delta \bx = \0$, it reduces to
\begin{equation}
\partial^2 \bv[\0] = \partial \bc \cdot \left(\frac{a-1}{\bx}\right)_\bI \: .
\end{equation}
This notion of `approximated approximations' was first introduced, in this manner, by Groenwold \emph{et al.}~\cite{groenwold2010approximated}. In significant practical terms, the 2nd-order Taylor expansion allows for a completely flexible and general interface with common polynomial time (subproblem) solvers, which are typically fed (as cheaply as possible) by the first and second-order information of the subproblem at different values of $\Delta \bx$\footnote{Even if linear programming is applied to solve the subproblem $\mathcal{S}$, the (variable) first-order information $\partial \bm{\nu} [\Delta \bx] = \partial \bv + \partial^2 \bv \cdot (\bx + \Delta \bx)$ will be supplied, iteratively.}. 

\section{Quadratic programs and the necesary conditions}

\emph{in rough drafting}
Take the curvature as constant. Use only diagonal information. Ensure it is convex.

Then we arrive at a convenient computational `kernel': the quadratic program (QP)\footnote{Conceptually, the step-wise solving of QP problems in general, non-linear programming, can be seen as equivalent to the way in which a linear system-solve is the `kernel' in nonlinear structural analysis. That is the `kernel' of the Newton-Rhapson method.}. In simple terms, polynomial time solution methods for QPs are often the cheapest, fastest, simplest to implement, interface, and most readily available (to an average computational engineer), and ... for subproblem $\mathcal{S}$, given some straight-forward conditions. See for example the recently released implementation by Boyd and collaborators~\cite{osqp}.  

TO BE COMPLETED

Eventually we arrive rather naturally at the necessary conditions: How far can we go, before we have to evaluate the problem again..? Keeping in mind, that we can not afford to evaluate the problem an excessive number of times... etc. etc. Move limits and estimates of nonlinear information (surrogate functions/problems, second order estimates).... upon convergence / when we can stop, we get something for free: the necessary conditions are satisfied / we have arrived at the necessary conditions in a rather practical way. Done.

% BIBLIOGRAPHY

\section*{Background}

The introduction to the `Elements of Structural Optimization' by Haftka, G\"urdal and Kamat~\cite{haftka1990}. The review of sensitivity analysis in structural optimization by van Keulen, Haftka and Kim~\cite{keulen2005}. More to follow. 

\bibliographystyle{unsrt} 
\addcontentsline{toc}{chapter}{References} 
\bibliography{./bib.bib} 

\end{document}
